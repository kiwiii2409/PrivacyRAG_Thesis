@book{latex,
  title = {LaTeX : A Documentation Preparation System User's Guide and Reference Manual},
  publisher = {Addison-Wesley Professional},
  year = {1994},
  author = {Leslie Lamport}
}

@misc{ragSAGE,
      title={Mitigating the Privacy Issues in Retrieval-Augmented Generation (RAG) via Pure Synthetic Data}, 
      author={Shenglai Zeng and Jiankun Zhang and Pengfei He and Jie Ren and Tianqi Zheng and Hanqing Lu and Han Xu and Hui Liu and Yue Xing and Jiliang Tang},
      year={2025},
      eprint={2406.14773},
      archivePrefix={arXiv},
      primaryClass={cs.CR},
      url={https://arxiv.org/abs/2406.14773}, 
}


@misc{goodAndBad,
      title={The Good and The Bad: Exploring Privacy Issues in Retrieval-Augmented Generation (RAG)}, 
      author={Shenglai Zeng and Jiankun Zhang and Pengfei He and Yue Xing and Yiding Liu and Han Xu and Jie Ren and Shuaiqiang Wang and Dawei Yin and Yi Chang and Jiliang Tang},
      year={2024},
      eprint={2402.16893},
      archivePrefix={arXiv},
      primaryClass={cs.CR},
      url={https://arxiv.org/abs/2402.16893}, 
}

@misc{eraser4RAG,
      title={Learning to Erase Private Knowledge from Multi-Documents for Retrieval-Augmented Large Language Models}, 
      author={Yujing Wang and Hainan Zhang and Liang Pang and Yongxin Tong and Binghui Guo and Hongwei Zheng and Zhiming Zheng},
      year={2025},
      eprint={2504.09910},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2504.09910}, 
}

@misc{generatingIsBelieving,
      title={Generating Is Believing: Membership Inference Attacks against Retrieval-Augmented Generation}, 
      author={Yuying Li and Gaoyang Liu and Chen Wang and Yang Yang},
      year={2024},
      eprint={2406.19234},
      archivePrefix={arXiv},
      primaryClass={cs.CR},
      url={https://arxiv.org/abs/2406.19234}, 
}
@misc{silentLeaks,
      title={Silent Leaks: Implicit Knowledge Extraction Attack on RAG Systems through Benign Queries}, 
      author={Yuhao Wang and Wenjie Qu and Yanze Jiang and Zichen Liu and Yue Liu and Shengfang Zhai and Yinpeng Dong and Jiaheng Zhang},
      year={2025},
      eprint={2505.15420},
      archivePrefix={arXiv},
      primaryClass={cs.CR},
      url={https://arxiv.org/abs/2505.15420}, 
}
@misc{targetingTheCore,
      title={Targeting the Core: A Simple and Effective Method to Attack RAG-based Agents via Direct LLM Manipulation}, 
      author={Xuying Li and Zhuo Li and Yuji Kosuga and Yasuhiro Yoshida and Victor Bian},
      year={2024},
      eprint={2412.04415},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
      url={https://arxiv.org/abs/2412.04415}, 
}

@misc{extractingTrainingDataLLM,
      title={Extracting Training Data from Large Language Models}, 
      author={Nicholas Carlini and Florian Tramer and Eric Wallace and Matthew Jagielski and Ariel Herbert-Voss and Katherine Lee and Adam Roberts and Tom Brown and Dawn Song and Ulfar Erlingsson and Alina Oprea and Colin Raffel},
      year={2021},
      eprint={2012.07805},
      archivePrefix={arXiv},
      primaryClass={cs.CR},
      url={https://arxiv.org/abs/2012.07805}, 
}

@misc{implicationsRAG,
      title={Privacy Implications of Retrieval-Based Language Models}, 
      author={Yangsibo Huang and Samyak Gupta and Zexuan Zhong and Kai Li and Danqi Chen},
      year={2023},
      eprint={2305.14888},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2305.14888}, 
}

@misc{ragOrigin,
      title={Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks}, 
      author={Patrick Lewis and Ethan Perez and Aleksandra Piktus and Fabio Petroni and Vladimir Karpukhin and Naman Goyal and Heinrich Küttler and Mike Lewis and Wen-tau Yih and Tim Rocktäschel and Sebastian Riedel and Douwe Kiela},
      year={2021},
      eprint={2005.11401},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2005.11401}, 
}

@inproceedings{ragMIA,
   title={Is My Data in Your Retrieval Database? Membership Inference Attacks Against Retrieval Augmented Generation},
   url={http://dx.doi.org/10.5220/0013108300003899},
   DOI={10.5220/0013108300003899},
   booktitle={Proceedings of the 11th International Conference on Information Systems Security and Privacy},
   publisher={SCITEPRESS - Science and Technology Publications},
   author={Anderson, Maya and Amit, Guy and Goldsteen, Abigail},
   year={2025},
   pages={474–485} }



@misc{ragThief,
      title={Feedback-Guided Extraction of Knowledge Base from Retrieval-Augmented LLM Applications}, 
      author={Changyue Jiang and Xudong Pan and Geng Hong and Chenfu Bao and Yang Chen and Min Yang},
      year={2025},
      eprint={2411.14110},
      archivePrefix={arXiv},
      primaryClass={cs.CR},
      url={https://arxiv.org/abs/2411.14110}, 
}


@misc{ragDP,
      title={Privacy-Preserving Retrieval-Augmented Generation with Differential Privacy}, 
      author={Tatsuki Koga and Ruihan Wu and Kamalika Chaudhuri},
      year={2025},
      eprint={2412.04697},
      archivePrefix={arXiv},
      primaryClass={cs.CR},
      url={https://arxiv.org/abs/2412.04697}, 
}


@misc{modelChoiceRAG,
      title={On the Influence of Context Size and Model Choice in Retrieval-Augmented Generation Systems}, 
      author={Juraj Vladika and Florian Matthes},
      year={2025},
      eprint={2502.14759},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2502.14759}, 
}

@misc{llmJudgeSurvey,
      title={LLMs-as-Judges: A Comprehensive Survey on LLM-based Evaluation Methods}, 
      author={Haitao Li and Qian Dong and Junjie Chen and Huixue Su and Yujia Zhou and Qingyao Ai and Ziyi Ye and Yiqun Liu},
      year={2024},
      eprint={2412.05579},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2412.05579}, 
}

@misc{DEAL,
      title={{DEAL}: High-Efficacy Privacy Attack on Retrieval-Augmented Generation Systems via {LLM} Optimizer},
      author={Tailai Zhang and Yuxuan Jiang and Ruihan Gong and Pan Zhou and Wen Yin and Xingxing Wei and Lixing Chen and Daizong Liu},
      year={2025},
      url={https://openreview.net/forum?id=sx8dtyZT41}
}

@article{LPRAG,
      author = {He, Longzhu and Tang, Peng and Zhang, Yuanhe and Zhou, Pengpeng and Su, Sen},
      title = {Mitigating privacy risks in Retrieval-Augmented Generation via locally private entity perturbation},
      year = {2025},
      issue_date = {Jul 2025},
      publisher = {Pergamon Press, Inc.},
      address = {USA},
      volume = {62},
      number = {4},
      issn = {0306-4573},
      url = {https://doi.org/10.1016/j.ipm.2025.104150},
      doi = {10.1016/j.ipm.2025.104150},
      journal = {Inf. Process. Manage.},
      month = may,
      numpages = {14},
      keywords = {Retrieval-augmented generation, Large language model, Local differential privacy, Privacy-preserving}
      }
@misc{DPVoteRAG,
      title={Privacy-Preserving Retrieval-Augmented Generation with Differential Privacy}, 
      author={Tatsuki Koga and Ruihan Wu and Kamalika Chaudhuri},
      year={2025},
      eprint={2412.04697},
      archivePrefix={arXiv},
      primaryClass={cs.CR},
      url={https://arxiv.org/abs/2412.04697}, 
}



@misc{spillTheBeans,
      title={Follow My Instruction and Spill the Beans: Scalable Data Extraction from Retrieval-Augmented Generation Systems}, 
      author={Zhenting Qi and Hanlin Zhang and Eric Xing and Sham Kakade and Himabindu Lakkaraju},
      year={2024},
      eprint={2402.17840},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2402.17840}, 
}

@misc{aresRAGEval,
      title={ARES: An Automated Evaluation Framework for Retrieval-Augmented Generation Systems}, 
      author={Jon Saad-Falcon and Omar Khattab and Christopher Potts and Matei Zaharia},
      year={2024},
      eprint={2311.09476},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2311.09476}, 
}

@misc{bertScore,
      title={BERTScore: Evaluating Text Generation with BERT}, 
      author={Tianyi Zhang and Varsha Kishore and Felix Wu and Kilian Q. Weinberger and Yoav Artzi},
      year={2020},
      eprint={1904.09675},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/1904.09675}, 
}

@inproceedings{rougeScore,
    title = "{ROUGE}: A Package for Automatic Evaluation of Summaries",
    author = "Lin, Chin-Yew",
    booktitle = "Text Summarization Branches Out",
    month = jul,
    year = "2004",
    address = "Barcelona, Spain",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/W04-1013/",
    pages = "74--81"
}

@misc{proactivePrivAmnesiaLLM,
      title={Proactive Privacy Amnesia for Large Language Models: Safeguarding PII with Negligible Impact on Model Utility}, 
      author={Martin Kuo and Jingyang Zhang and Jianyi Zhang and Minxue Tang and Louis DiValentin and Aolin Ding and Jingwei Sun and William Chen and Amin Hass and Tianlong Chen and Yiran Chen and Hai Li},
      year={2025},
      eprint={2502.17591},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2502.17591}, 
}

@inproceedings{netflixDeAnon,
  author={Narayanan, Arvind and Shmatikov, Vitaly},
  booktitle={2008 IEEE Symposium on Security and Privacy (sp 2008)}, 
  title={Robust De-anonymization of Large Sparse Datasets}, 
  year={2008},
  volume={},
  number={},
  pages={111-125},
  keywords={Robustness;Motion pictures;Data security;Data privacy;Transaction databases;Data mining;Internet;Tail;Probability;DVD;Privacy;Anonymity;Attack},
  doi={10.1109/SP.2008.33}}

@article{simpleDemographic,
author = "Latanya  Sweeney",
title = "{Simple Demographics Often Identify People Uniquely}",
year = "2018",
month = "6",
url = "https://kilthub.cmu.edu/articles/journal_contribution/Simple_Demographics_Often_Identify_People_Uniquely/6625769",
doi = "10.1184/R1/6625769.v1"
}

@misc{anonDefinition,
    title = {10 Misunderstandings Related to Anonymisation},
    author = {{European Data Protection Supervisor (EDPS)} and {Agencia Española de Protección de Datos (AEPD)}},
    year = {2021},
    url = {https://www.edps.europa.eu/system/files/2021-04/21-04-27_aepd-edps_anonymisation_en_5.pdf},
    note = {Accessed on September 10, 2025}
}


@misc{microsoft_presidio,
  author = {{Microsoft}},
  title = {{Presidio: An open-source library for data privacy}},
  howpublished = {\url{https://microsoft.github.io/presidio/}},
  year = {2025},
  note = {Accessed on September 10, 2025}
}

@misc{aws_secure_rag,
  author = {{AWS Machine Learning Blog}},
  title = {{Secure RAG applications using prompt engineering on Amazon Bedrock}},
  howpublished = {\url{https://aws.amazon.com/blogs/machine-learning/secure-rag-applications-using-prompt-engineering-on-amazon-bedrock/}},
  year = {2025}, % Based on current date context as the blog post does not contain a specific date.
  note = {Accessed on September 10, 2025}
}

@article{aws_bedrock_privacy,
title={Protect sensitive data in RAG applications with Amazon Bedrock},
author={Chamarthi, Praveen and Rooks, Brandon and Patel, Dhawalkumar and Reddy, Srikanth and Garg, Vikash and Bhadauria, Vivek},
journal={AWS Machine Learning Blog},
year={2025},
month={April},
url={https://aws.amazon.com/blogs/machine-learning/protect-sensitive-data-in-rag-applications-with-amazon-bedrock/}
}


@misc{anthropic_strengthen_guardrails,
  title = {Strengthen Guardrails},
  author = {{Anthropic}},
  howpublished = {\url{https://docs.anthropic.com/en/docs/test-and-evaluate/strengthen-guardrails}},
  year = {2025},
  note = {Accessed on September 10, 2025}
}


@inproceedings{bypassingLLMGuardrails,
    title = "Bypassing {LLM} Guardrails: An Empirical Analysis of Evasion Attacks against Prompt Injection and Jailbreak Detection Systems",
    author = "Hackett, William  and
      Birch, Lewis  and
      Trawicki, Stefan  and
      Suri, Neeraj  and
      Garraghan, Peter",
    editor = "Derczynski, Leon  and
      Novikova, Jekaterina  and
      Chen, Muhao",
    booktitle = "Proceedings of the The First Workshop on LLM Security (LLMSEC)",
    month = aug,
    year = "2025",
    address = "Vienna, Austria",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2025.llmsec-1.8/",
    pages = "101--114",
    ISBN = "979-8-89176-279-4",
    abstract = "Large Language Models (LLMs) guardrail systems are designed to protect against prompt injection and jailbreak attacks. However, they remain vulnerable to evasion techniques. We demonstrate two approaches for bypassing LLM prompt injection and jailbreak detection systems via traditional character injection methods and algorithmic Adversarial Machine Learning (AML) evasion techniques. Through testing against six prominent protection systems, including Microsoft{'}s Azure Prompt Shield and Meta{'}s Prompt Guard, we show that both methods can be used to evade detection while maintaining adversarial utility achieving in some instances up to 100{\%} evasion success. Furthermore, we demonstrate that adversaries can enhance Attack Success Rates (ASR) against black-box targets by leveraging word importance ranking computed by offline white-box models. Our findings reveal vulnerabilities within current LLM protection mechanisms and highlight the need for more robust guardrail systems."
}

@misc{copyBreakRAG,
      title={Feedback-Guided Extraction of Knowledge Base from Retrieval-Augmented LLM Applications}, 
      author={Changyue Jiang and Xudong Pan and Geng Hong and Chenfu Bao and Yang Chen and Min Yang},
      year={2025},
      eprint={2411.14110},
      archivePrefix={arXiv},
      primaryClass={cs.CR},
      url={https://arxiv.org/abs/2411.14110}, 
}


@misc{mixtralModel,
      title={Mixtral of Experts}, 
      author={Albert Q. Jiang and Alexandre Sablayrolles and Antoine Roux and Arthur Mensch and Blanche Savary and Chris Bamford and Devendra Singh Chaplot and Diego de las Casas and Emma Bou Hanna and Florian Bressand and Gianna Lengyel and Guillaume Bour and Guillaume Lample and Lélio Renard Lavaud and Lucile Saulnier and Marie-Anne Lachaux and Pierre Stock and Sandeep Subramanian and Sophia Yang and Szymon Antoniak and Teven Le Scao and Théophile Gervet and Thibaut Lavril and Thomas Wang and Timothée Lacroix and William El Sayed},
      year={2024},
      eprint={2401.04088},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2401.04088}, 
}

@article{llama3Model,
  title={Llama 3 Model Card},
  author={AI@Meta},
  year={2024},
  url = {https://github.com/meta-llama/llama3/blob/main/MODEL_CARD.md}
}

@inproceedings{gpt4Model,
  title={GPT-4 Technical Report},
  author={OpenAI Josh Achiam and Steven Adler and Sandhini Agarwal and Lama Ahmad and Ilge Akkaya and Florencia Leoni Aleman and Diogo Almeida and Janko Altenschmidt and Sam Altman and Shyamal Anadkat and Red Avila and Igor Babuschkin and Suchir Balaji and Valerie Balcom and Paul Baltescu and Haim-ing Bao and Mo Bavarian and Jeff Belgum and Irwan Bello and Jake Berdine and Gabriel Bernadett-Shapiro and Christopher Berner and Lenny Bogdonoff and Oleg Boiko and Made-laine Boyd and Anna-Luisa Brakman and Greg Brockman and Tim Brooks and Miles Brundage and Kevin Button and Trevor Cai and Rosie Campbell and Andrew Cann and Brittany Carey and Chelsea Carlson and Rory Carmichael and Brooke Chan and Che Chang and Fotis Chantzis and Derek Chen and Sully Chen and Ruby Chen and Jason Chen and Mark Chen and Benjamin Chess and Chester Cho and Casey Chu and Hyung Won Chung and Dave Cummings and Jeremiah Currier and Yunxing Dai and Cory Decareaux and Thomas Degry and Noah Deutsch and Damien Deville and Arka Dhar and David Dohan and Steve Dowling and Sheila Dunning and Adrien Ecoffet and Atty Eleti and Tyna Eloundou and David Farhi and Liam Fedus and Niko Felix and Sim'on Posada Fishman and Juston Forte and Is-abella Fulford and Leo Gao and Elie Georges and Christian Gibson and Vik Goel and Tarun Gogineni and Gabriel Goh and Raphael Gontijo-Lopes and Jonathan Gordon and Morgan Grafstein and Scott Gray and Ryan Greene and Joshua Gross and Shixiang Shane Gu and Yufei Guo and Chris Hallacy and Jesse Han and Jeff Harris and Yuchen He and Mike Heaton and Johannes Heidecke and Chris Hesse and Alan Hickey and Wade Hickey and Peter Hoeschele and Brandon Houghton and Kenny Hsu and Shengli Hu and Xin Hu and Joost Huizinga and Shantanu Jain and Shawn Jain and Joanne Jang and Angela Jiang and Roger Jiang and Haozhun Jin and Denny Jin and Shino Jomoto and Billie Jonn and Heewoo Jun and Tomer Kaftan and Lukasz Kaiser and Ali Kamali and Ingmar Kanitscheider and Nitish Shirish Keskar and Tabarak Khan and Logan Kilpatrick and Jong Wook Kim and Christina Kim and Yongjik Kim and Hendrik Kirchner and Jamie Ryan Kiros and Matthew Knight and Daniel Kokotajlo and Lukasz Kondraciuk and Andrew Kondrich and Aris Konstantinidis and Kyle Kosic and Gretchen Krueger and Vishal Kuo and Michael Lampe and Ikai Lan and Teddy Lee and Jan Leike and Jade Leung and Daniel Levy and Chak Li and Rachel Lim and Molly Lin and Stephanie Lin and Ma-teusz Litwin and Theresa Lopez and Ryan Lowe and Patricia Lue and Anna Makanju and Kim Malfacini and Sam Manning and Todor Markov and Yaniv Markovski and Bianca Martin and Katie Mayer and Andrew Mayne and Bob McGrew and Scott Mayer McKinney and Christine McLeavey and Paul McMillan and Jake McNeil and David Medina and Aalok Mehta and Jacob Menick and Luke Metz and An-drey Mishchenko and Pamela Mishkin and Vinnie Monaco and Evan Morikawa and Daniel P. Mossing and Tong Mu and Mira Murati and Oleg Murk and David M'ely and Ashvin Nair and Reiichiro Nakano and Rajeev Nayak and Arvind Neelakantan and Richard Ngo and Hyeonwoo Noh and Ouyang Long and Cullen O'Keefe and Jakub W. Pachocki and Alex Paino and Joe Palermo and Ashley Pantuliano and Giambattista Parascandolo and Joel Parish and Emy Parparita and Alexandre Passos and Mikhail Pavlov and Andrew Peng and Adam Perelman and Filipe de Avila Belbute Peres and Michael Petrov and Henrique Pond{\'e} de Oliveira Pinto and Michael Pokorny and Michelle Pokrass and Vitchyr H. Pong and Tolly Powell and Alethea Power and Boris Power and Elizabeth Proehl and Raul Puri and Alec Radford and Jack W. Rae and Aditya Ramesh and Cameron Raymond and Francis Real and Kendra Rimbach and Carl Ross and Bob Rotsted and Henri Roussez and Nick Ryder and Mario D. Saltarelli and Ted Sanders and Shibani Santurkar and Girish Sastry and Heather Schmidt and David Schnurr and John Schulman and Daniel Selsam and Kyla Sheppard and Toki Sherbakov and Jessica Shieh and Sarah Shoker and Pranav Shyam and Szymon Sidor and Eric Sigler and Maddie Simens and Jordan Sitkin and Katarina Slama and Ian Sohl and Benjamin Sokolowsky and Yang Song and Natalie Staudacher and Felipe Petroski Such and Natalie Summers and Ilya Sutskever and Jie Tang and Nikolas A. Tezak and Madeleine Thompson and Phil Tillet and Amin Tootoonchian and Elizabeth Tseng and Preston Tuggle and Nick Turley and Jerry Tworek and Juan Felipe Cer'on Uribe and Andrea Vallone and Arun Vijayvergiya and Chelsea Voss and Carroll L. Wainwright and Justin Jay Wang and Alvin Wang and Ben Wang and Jonathan Ward and Jason Wei and CJ Weinmann and Akila Welihinda and Peter Welinder and Jiayi Weng and Lilian Weng and Matt Wiethoff and Dave Willner and Clemens Winter and Samuel Wolrich and Hannah Wong and Lauren Workman and Sherwin Wu and Jeff Wu and Michael Wu and Kai Xiao and Tao Xu and Sarah Yoo and Kevin Yu and Qim-ing Yuan and Wojciech Zaremba and Rowan Zellers and Chong Zhang and Marvin Zhang and Shengjia Zhao and Tianhao Zheng and Juntang Zhuang and William Zhuk and Barret Zoph},
  year={2023},
  url={https://api.semanticscholar.org/CorpusID:257532815}
}

@misc{gpt4oModel,
      title={GPT-4o System Card}, 
      author={OpenAI and : and Aaron Hurst and Adam Lerer and Adam P. Goucher and Adam Perelman and Aditya Ramesh and Aidan Clark and AJ Ostrow and Akila Welihinda and Alan Hayes and Alec Radford and Aleksander Mądry and Alex Baker-Whitcomb and Alex Beutel and Alex Borzunov and Alex Carney and Alex Chow and Alex Kirillov and Alex Nichol and Alex Paino and Alex Renzin and Alex Tachard Passos and Alexander Kirillov and Alexi Christakis and Alexis Conneau and Ali Kamali and Allan Jabri and Allison Moyer and Allison Tam and Amadou Crookes and Amin Tootoochian and Amin Tootoonchian and Ananya Kumar and Andrea Vallone and Andrej Karpathy and Andrew Braunstein and Andrew Cann and Andrew Codispoti and Andrew Galu and Andrew Kondrich and Andrew Tulloch and Andrey Mishchenko and Angela Baek and Angela Jiang and Antoine Pelisse and Antonia Woodford and Anuj Gosalia and Arka Dhar and Ashley Pantuliano and Avi Nayak and Avital Oliver and Barret Zoph and Behrooz Ghorbani and Ben Leimberger and Ben Rossen and Ben Sokolowsky and Ben Wang and Benjamin Zweig and Beth Hoover and Blake Samic and Bob McGrew and Bobby Spero and Bogo Giertler and Bowen Cheng and Brad Lightcap and Brandon Walkin and Brendan Quinn and Brian Guarraci and Brian Hsu and Bright Kellogg and Brydon Eastman and Camillo Lugaresi and Carroll Wainwright and Cary Bassin and Cary Hudson and Casey Chu and Chad Nelson and Chak Li and Chan Jun Shern and Channing Conger and Charlotte Barette and Chelsea Voss and Chen Ding and Cheng Lu and Chong Zhang and Chris Beaumont and Chris Hallacy and Chris Koch and Christian Gibson and Christina Kim and Christine Choi and Christine McLeavey and Christopher Hesse and Claudia Fischer and Clemens Winter and Coley Czarnecki and Colin Jarvis and Colin Wei and Constantin Koumouzelis and Dane Sherburn and Daniel Kappler and Daniel Levin and Daniel Levy and David Carr and David Farhi and David Mely and David Robinson and David Sasaki and Denny Jin and Dev Valladares and Dimitris Tsipras and Doug Li and Duc Phong Nguyen and Duncan Findlay and Edede Oiwoh and Edmund Wong and Ehsan Asdar and Elizabeth Proehl and Elizabeth Yang and Eric Antonow and Eric Kramer and Eric Peterson and Eric Sigler and Eric Wallace and Eugene Brevdo and Evan Mays and Farzad Khorasani and Felipe Petroski Such and Filippo Raso and Francis Zhang and Fred von Lohmann and Freddie Sulit and Gabriel Goh and Gene Oden and Geoff Salmon and Giulio Starace and Greg Brockman and Hadi Salman and Haiming Bao and Haitang Hu and Hannah Wong and Haoyu Wang and Heather Schmidt and Heather Whitney and Heewoo Jun and Hendrik Kirchner and Henrique Ponde de Oliveira Pinto and Hongyu Ren and Huiwen Chang and Hyung Won Chung and Ian Kivlichan and Ian O'Connell and Ian O'Connell and Ian Osband and Ian Silber and Ian Sohl and Ibrahim Okuyucu and Ikai Lan and Ilya Kostrikov and Ilya Sutskever and Ingmar Kanitscheider and Ishaan Gulrajani and Jacob Coxon and Jacob Menick and Jakub Pachocki and James Aung and James Betker and James Crooks and James Lennon and Jamie Kiros and Jan Leike and Jane Park and Jason Kwon and Jason Phang and Jason Teplitz and Jason Wei and Jason Wolfe and Jay Chen and Jeff Harris and Jenia Varavva and Jessica Gan Lee and Jessica Shieh and Ji Lin and Jiahui Yu and Jiayi Weng and Jie Tang and Jieqi Yu and Joanne Jang and Joaquin Quinonero Candela and Joe Beutler and Joe Landers and Joel Parish and Johannes Heidecke and John Schulman and Jonathan Lachman and Jonathan McKay and Jonathan Uesato and Jonathan Ward and Jong Wook Kim and Joost Huizinga and Jordan Sitkin and Jos Kraaijeveld and Josh Gross and Josh Kaplan and Josh Snyder and Joshua Achiam and Joy Jiao and Joyce Lee and Juntang Zhuang and Justyn Harriman and Kai Fricke and Kai Hayashi and Karan Singhal and Katy Shi and Kavin Karthik and Kayla Wood and Kendra Rimbach and Kenny Hsu and Kenny Nguyen and Keren Gu-Lemberg and Kevin Button and Kevin Liu and Kiel Howe and Krithika Muthukumar and Kyle Luther and Lama Ahmad and Larry Kai and Lauren Itow and Lauren Workman and Leher Pathak and Leo Chen and Li Jing and Lia Guy and Liam Fedus and Liang Zhou and Lien Mamitsuka and Lilian Weng and Lindsay McCallum and Lindsey Held and Long Ouyang and Louis Feuvrier and Lu Zhang and Lukas Kondraciuk and Lukasz Kaiser and Luke Hewitt and Luke Metz and Lyric Doshi and Mada Aflak and Maddie Simens and Madelaine Boyd and Madeleine Thompson and Marat Dukhan and Mark Chen and Mark Gray and Mark Hudnall and Marvin Zhang and Marwan Aljubeh and Mateusz Litwin and Matthew Zeng and Max Johnson and Maya Shetty and Mayank Gupta and Meghan Shah and Mehmet Yatbaz and Meng Jia Yang and Mengchao Zhong and Mia Glaese and Mianna Chen and Michael Janner and Michael Lampe and Michael Petrov and Michael Wu and Michele Wang and Michelle Fradin and Michelle Pokrass and Miguel Castro and Miguel Oom Temudo de Castro and Mikhail Pavlov and Miles Brundage and Miles Wang and Minal Khan and Mira Murati and Mo Bavarian and Molly Lin and Murat Yesildal and Nacho Soto and Natalia Gimelshein and Natalie Cone and Natalie Staudacher and Natalie Summers and Natan LaFontaine and Neil Chowdhury and Nick Ryder and Nick Stathas and Nick Turley and Nik Tezak and Niko Felix and Nithanth Kudige and Nitish Keskar and Noah Deutsch and Noel Bundick and Nora Puckett and Ofir Nachum and Ola Okelola and Oleg Boiko and Oleg Murk and Oliver Jaffe and Olivia Watkins and Olivier Godement and Owen Campbell-Moore and Patrick Chao and Paul McMillan and Pavel Belov and Peng Su and Peter Bak and Peter Bakkum and Peter Deng and Peter Dolan and Peter Hoeschele and Peter Welinder and Phil Tillet and Philip Pronin and Philippe Tillet and Prafulla Dhariwal and Qiming Yuan and Rachel Dias and Rachel Lim and Rahul Arora and Rajan Troll and Randall Lin and Rapha Gontijo Lopes and Raul Puri and Reah Miyara and Reimar Leike and Renaud Gaubert and Reza Zamani and Ricky Wang and Rob Donnelly and Rob Honsby and Rocky Smith and Rohan Sahai and Rohit Ramchandani and Romain Huet and Rory Carmichael and Rowan Zellers and Roy Chen and Ruby Chen and Ruslan Nigmatullin and Ryan Cheu and Saachi Jain and Sam Altman and Sam Schoenholz and Sam Toizer and Samuel Miserendino and Sandhini Agarwal and Sara Culver and Scott Ethersmith and Scott Gray and Sean Grove and Sean Metzger and Shamez Hermani and Shantanu Jain and Shengjia Zhao and Sherwin Wu and Shino Jomoto and Shirong Wu and Shuaiqi and Xia and Sonia Phene and Spencer Papay and Srinivas Narayanan and Steve Coffey and Steve Lee and Stewart Hall and Suchir Balaji and Tal Broda and Tal Stramer and Tao Xu and Tarun Gogineni and Taya Christianson and Ted Sanders and Tejal Patwardhan and Thomas Cunninghman and Thomas Degry and Thomas Dimson and Thomas Raoux and Thomas Shadwell and Tianhao Zheng and Todd Underwood and Todor Markov and Toki Sherbakov and Tom Rubin and Tom Stasi and Tomer Kaftan and Tristan Heywood and Troy Peterson and Tyce Walters and Tyna Eloundou and Valerie Qi and Veit Moeller and Vinnie Monaco and Vishal Kuo and Vlad Fomenko and Wayne Chang and Weiyi Zheng and Wenda Zhou and Wesam Manassra and Will Sheu and Wojciech Zaremba and Yash Patil and Yilei Qian and Yongjik Kim and Youlong Cheng and Yu Zhang and Yuchen He and Yuchen Zhang and Yujia Jin and Yunxing Dai and Yury Malkov},
      year={2024},
      eprint={2410.21276},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2410.21276}, 
}

@misc{gptossModel,
      title={gpt-oss-120b & gpt-oss-20b Model Card}, 
      author={OpenAI and : and Sandhini Agarwal and Lama Ahmad and Jason Ai and Sam Altman and Andy Applebaum and Edwin Arbus and Rahul K. Arora and Yu Bai and Bowen Baker and Haiming Bao and Boaz Barak and Ally Bennett and Tyler Bertao and Nivedita Brett and Eugene Brevdo and Greg Brockman and Sebastien Bubeck and Che Chang and Kai Chen and Mark Chen and Enoch Cheung and Aidan Clark and Dan Cook and Marat Dukhan and Casey Dvorak and Kevin Fives and Vlad Fomenko and Timur Garipov and Kristian Georgiev and Mia Glaese and Tarun Gogineni and Adam Goucher and Lukas Gross and Katia Gil Guzman and John Hallman and Jackie Hehir and Johannes Heidecke and Alec Helyar and Haitang Hu and Romain Huet and Jacob Huh and Saachi Jain and Zach Johnson and Chris Koch and Irina Kofman and Dominik Kundel and Jason Kwon and Volodymyr Kyrylov and Elaine Ya Le and Guillaume Leclerc and James Park Lennon and Scott Lessans and Mario Lezcano-Casado and Yuanzhi Li and Zhuohan Li and Ji Lin and Jordan Liss and Lily and Liu and Jiancheng Liu and Kevin Lu and Chris Lu and Zoran Martinovic and Lindsay McCallum and Josh McGrath and Scott McKinney and Aidan McLaughlin and Song Mei and Steve Mostovoy and Tong Mu and Gideon Myles and Alexander Neitz and Alex Nichol and Jakub Pachocki and Alex Paino and Dana Palmie and Ashley Pantuliano and Giambattista Parascandolo and Jongsoo Park and Leher Pathak and Carolina Paz and Ludovic Peran and Dmitry Pimenov and Michelle Pokrass and Elizabeth Proehl and Huida Qiu and Gaby Raila and Filippo Raso and Hongyu Ren and Kimmy Richardson and David Robinson and Bob Rotsted and Hadi Salman and Suvansh Sanjeev and Max Schwarzer and D. Sculley and Harshit Sikchi and Kendal Simon and Karan Singhal and Yang Song and Dane Stuckey and Zhiqing Sun and Philippe Tillet and Sam Toizer and Foivos Tsimpourlas and Nikhil Vyas and Eric Wallace and Xin Wang and Miles Wang and Olivia Watkins and Kevin Weil and Amy Wendling and Kevin Whinnery and Cedric Whitney and Hannah Wong and Lin Yang and Yu Yang and Michihiro Yasunaga and Kristen Ying and Wojciech Zaremba and Wenting Zhan and Cyril Zhang and Brian Zhang and Eddie Zhang and Shengjia Zhao},
      year={2025},
      eprint={2508.10925},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2508.10925}, 
}



@article{NQ,
    title = "Natural Questions: A Benchmark for Question Answering Research",
    author = "Kwiatkowski, Tom  and
      Palomaki, Jennimaria  and
      Redfield, Olivia  and
      Collins, Michael  and
      Parikh, Ankur  and
      Alberti, Chris  and
      Epstein, Danielle  and
      Polosukhin, Illia  and
      Devlin, Jacob  and
      Lee, Kenton  and
      Toutanova, Kristina  and
      Jones, Llion  and
      Kelcey, Matthew  and
      Chang, Ming-Wei  and
      Dai, Andrew M.  and
      Uszkoreit, Jakob  and
      Le, Quoc  and
      Petrov, Slav",
    editor = "Lee, Lillian  and
      Johnson, Mark  and
      Roark, Brian  and
      Nenkova, Ani",
    journal = "Transactions of the Association for Computational Linguistics",
    volume = "7",
    year = "2019",
    address = "Cambridge, MA",
    publisher = "MIT Press",
    url = "https://aclanthology.org/Q19-1026/",
    doi = "10.1162/tacl_a_00276",
    pages = "452--466",
    abstract = "We present the Natural Questions corpus, a question answering data set. Questions consist of real anonymized, aggregated queries issued to the Google search engine. An annotator is presented with a question along with a Wikipedia page from the top 5 search results, and annotates a long answer (typically a paragraph) and a short answer (one or more entities) if present on the page, or marks null if no long/short answer is present. The public release consists of 307,373 training examples with single annotations; 7,830 examples with 5-way annotations for development data; and a further 7,842 examples with 5-way annotated sequestered as test data. We present experiments validating quality of the data. We also describe analysis of 25-way annotations on 302 examples, giving insights into human variability on the annotation task. We introduce robust metrics for the purposes of evaluating question answering systems; demonstrate high human upper bounds on these metrics; and establish baseline results using competitive methods drawn from related literature."
}

@inproceedings{TriviaQA,
    title = "{T}rivia{QA}: A Large Scale Distantly Supervised Challenge Dataset for Reading Comprehension",
    author = "Joshi, Mandar  and
      Choi, Eunsol  and
      Weld, Daniel  and
      Zettlemoyer, Luke",
    editor = "Barzilay, Regina  and
      Kan, Min-Yen",
    booktitle = "Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = jul,
    year = "2017",
    address = "Vancouver, Canada",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/P17-1147/",
    doi = "10.18653/v1/P17-1147",
    pages = "1601--1611",
    abstract = "We present TriviaQA, a challenging reading comprehension dataset containing over 650K question-answer-evidence triples. TriviaQA includes 95K question-answer pairs authored by trivia enthusiasts and independently gathered evidence documents, six per question on average, that provide high quality distant supervision for answering the questions. We show that, in comparison to other recently introduced large-scale datasets, TriviaQA (1) has relatively complex, compositional questions, (2) has considerable syntactic and lexical variability between questions and corresponding answer-evidence sentences, and (3) requires more cross sentence reasoning to find answers. We also present two baseline algorithms: a feature-based classifier and a state-of-the-art neural network, that performs well on SQuAD reading comprehension. Neither approach comes close to human performance (23{\%} and 40{\%} vs. 80{\%}), suggesting that TriviaQA is a challenging testbed that is worth significant future study."
}



MODS XML
Endnote
Preformatted
@inproceedings{popQA,
    title = "When Not to Trust Language Models: Investigating Effectiveness of Parametric and Non-Parametric Memories",
    author = "Mallen, Alex  and
      Asai, Akari  and
      Zhong, Victor  and
      Das, Rajarshi  and
      Khashabi, Daniel  and
      Hajishirzi, Hannaneh",
    editor = "Rogers, Anna  and
      Boyd-Graber, Jordan  and
      Okazaki, Naoaki",
    booktitle = "Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = jul,
    year = "2023",
    address = "Toronto, Canada",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2023.acl-long.546/",
    doi = "10.18653/v1/2023.acl-long.546",
    pages = "9802--9822",
    abstract = "Despite their impressive performance on diverse tasks, large language models (LMs) still struggle with tasks requiring rich world knowledge, implying the difficulty of encoding a wealth of world knowledge in their parameters. This paper aims to understand LMs' strengths and limitations in memorizing factual knowledge, by conducting large-scale knowledge probing experiments on two open-domain entity-centric QA datasets: PopQA, our new dataset with 14k questions about long-tail entities, and EntityQuestions, a widely used open-domain QA dataset. We find that LMs struggle with less popular factual knowledge, and that retrieval augmentation helps significantly in these cases. Scaling, on the other hand, mainly improves memorization of popular knowledge, and fails to appreciably improve memorization of factual knowledge in the tail. Based on those findings, we devise a new method for retrieval-augmentation that improves performance and reduces inference costs by only retrieving non-parametric memories when necessary."
}

@misc{hotpotQA,
      title={HotpotQA: A Dataset for Diverse, Explainable Multi-hop Question Answering}, 
      author={Zhilin Yang and Peng Qi and Saizheng Zhang and Yoshua Bengio and William W. Cohen and Ruslan Salakhutdinov and Christopher D. Manning},
      year={2018},
      eprint={1809.09600},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/1809.09600}, 
}


@misc{chatDoctor,
      title={ChatDoctor: A Medical Chat Model Fine-Tuned on a Large Language Model Meta-AI (LLaMA) Using Medical Domain Knowledge}, 
      author={Yunxiang Li and Zihan Li and Kai Zhang and Ruilong Dan and Steve Jiang and You Zhang},
      year={2023},
      eprint={2303.14070},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2303.14070}, 
}

@inproceedings{ragNoHallucination,
    title = "Retrieval Augmentation Reduces Hallucination in Conversation",
    author = "Shuster, Kurt  and
      Poff, Spencer  and
      Chen, Moya  and
      Kiela, Douwe  and
      Weston, Jason",
    editor = "Moens, Marie-Francine  and
      Huang, Xuanjing  and
      Specia, Lucia  and
      Yih, Scott Wen-tau",
    booktitle = "Findings of the Association for Computational Linguistics: EMNLP 2021",
    month = nov,
    year = "2021",
    address = "Punta Cana, Dominican Republic",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2021.findings-emnlp.320/",
    doi = "10.18653/v1/2021.findings-emnlp.320",
    pages = "3784--3803",
    abstract = "Despite showing increasingly human-like conversational abilities, state-of-the-art dialogue models often suffer from factual incorrectness and hallucination of knowledge (Roller et al., 2020). In this work we explore the use of neural-retrieval-in-the-loop architectures - recently shown to be effective in open-domain QA (Lewis et al., 2020b; Izacard and Grave, 2020) - for knowledge-grounded dialogue, a task that is arguably more challenging as it requires querying based on complex multi-turn dialogue context and generating conversationally coherent responses. We study various types of architectures with multiple components - retrievers, rankers, and encoder-decoders - with the goal of maximizing knowledgeability while retaining conversational ability. We demonstrate that our best models obtain state-of-the-art performance on two knowledge-grounded conversational tasks. The models exhibit open-domain conversational capabilities, generalize effectively to scenarios not within the training data, and, as verified by human evaluations, substantially reduce the well-known problem of knowledge hallucination in state-of-the-art chatbots."
}